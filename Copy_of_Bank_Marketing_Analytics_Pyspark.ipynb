{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswathy7576/Clustering-PySpark-Bank-Marketing-Data/blob/main/Copy_of_Bank_Marketing_Analytics_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK5KUqZ87EjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6841864e-2b5e-48bf-873a-1d70af041258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "#!ls\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/7153\")\n",
        "\n",
        "#!ls\n",
        "\n",
        "#https://drive.google.com/drive/folders/1Uy9FuGZ5i20ANW489QX5YknJCgUYFOrE?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-NDy5LXQWNa"
      },
      "outputs": [],
      "source": [
        "#!pip install wget\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsJEweQiR0c5"
      },
      "outputs": [],
      "source": [
        "#checking the existing installed java version\n",
        "#!java -version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEMZVHCefo8d"
      },
      "outputs": [],
      "source": [
        "#installing spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy_FKPtZgQ52"
      },
      "outputs": [],
      "source": [
        "#decompressing the zipped file in current directory in gdrive\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJm4dqkiguWn"
      },
      "outputs": [],
      "source": [
        "#setting the environment variables for spark\n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"]=\"/content/spark-3.0.0/spark-3.0.0-bin-hadoop3.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec2d_c7viD_2"
      },
      "outputs": [],
      "source": [
        "#installing findspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnmmM-puiJwR",
        "outputId": "c6298582-01c0-43d3-c0ca-6353d78f93ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.0.0\n",
            "  Downloading pyspark-3.0.0.tar.gz (204.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7 MB 22 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 23.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=ef3d5b6c211dd0c8053952a0a8de247b5690c17f4d52a9cb1766bd3c4bba22d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/c5/36/aef1bb711963a619063119cc032176106827a129c0be20e301\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ]
        }
      ],
      "source": [
        "#installing the matching pyspark version\n",
        "!pip install pyspark==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_qLjv7Dj9Gl"
      },
      "outputs": [],
      "source": [
        "import py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPTP6LDxkDSY"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIizQWpXkF78",
        "outputId": "d328f74e-237f-476f-db5e-0a3aa6e28a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0.0\n"
          ]
        }
      ],
      "source": [
        "#checking pyspark version\n",
        "print(pyspark.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsXPhYvqkkrf",
        "outputId": "f5facfa7-9d1c-411d-f6a5-4559958c9f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " bank-additional-full.csv                  master.csv\n",
            " bank.csv                                  \u001b[0m\u001b[01;34mspark-3.0.0-bin-hadoop3.2\u001b[0m/\n",
            " bank-full.csv                             spark-3.0.0-bin-hadoop3.2.tgz\n",
            "'Bank Marketing Analytics Pyspark.ipynb'   spark-3.0.0-bin-hadoop3.2.tgz.1\n",
            " bank_new.csv                              spark-3.0.0-bin-hadoop3.2.tgz.2\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S2h9IVdkxjB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import findspark\n",
        "findspark.init(\"spark-3.0.0-bin-hadoop3.2\")#SPARK_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wg89HyHpHYg"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.master(\"local\").appName(\"Search\").config(conf=SparkConf()).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bZvXlrmxG9",
        "outputId": "2dc006b7-6ae8-4afb-ab30-1886864308f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/session.py:378: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ]
        }
      ],
      "source": [
        "#creating a dataframe with columnames and value\n",
        "df=spark.createDataFrame([{\"language,usercount\" :(\"java,2000\")}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssav0qyGq-ky"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROsEWJNVp50o",
        "outputId": "c2395690-8dcb-4019-a37f-64fdcb9b100a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|language,usercount|\n",
            "+------------------+\n",
            "|         java,2000|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOcMz9Jbwq_Q"
      },
      "source": [
        "**Bank Marketing EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTvJpD0X2Dc7"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName('Bank Marketing Analytics').getOrCreate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O0AOdCB2kLQ"
      },
      "outputs": [],
      "source": [
        "#IMPORTING suicide rate  DATASET AS A SPARK DATA FRAME\n",
        "df = spark.read.csv('bank_new.csv', header = True, inferSchema = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n08CltMVV8gr",
        "outputId": "be7836b2-09ee-4722-ba05-71e62b1bfccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|        job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "| 59|     admin.| married|secondary|     no|   2343|    yes|  no|unknown|  5|  may|    1042|       1|   -1|       0| unknown|    yes|\n",
            "| 56|     admin.| married|secondary|     no|     45|     no|  no|unknown|  5|  may|    1467|       1|   -1|       0| unknown|    yes|\n",
            "| 41| technician| married|secondary|     no|   1270|    yes|  no|unknown|  5|  may|    1389|       1|   -1|       0| unknown|    yes|\n",
            "| 55|   services| married|secondary|     no|   2476|    yes|  no|unknown|  5|  may|     579|       1|   -1|       0| unknown|    yes|\n",
            "| 54|     admin.| married| tertiary|     no|    184|     no|  no|unknown|  5|  may|     673|       2|   -1|       0| unknown|    yes|\n",
            "| 42| management|  single| tertiary|     no|      0|    yes| yes|unknown|  5|  may|     562|       2|   -1|       0| unknown|    yes|\n",
            "| 56| management| married| tertiary|     no|    830|    yes| yes|unknown|  6|  may|    1201|       1|   -1|       0| unknown|    yes|\n",
            "| 60|    retired|divorced|secondary|     no|    545|    yes|  no|unknown|  6|  may|    1030|       1|   -1|       0| unknown|    yes|\n",
            "| 37| technician| married|secondary|     no|      1|    yes|  no|unknown|  6|  may|     608|       1|   -1|       0| unknown|    yes|\n",
            "| 28|   services|  single|secondary|     no|   5090|    yes|  no|unknown|  6|  may|    1297|       3|   -1|       0| unknown|    yes|\n",
            "| 38|     admin.|  single|secondary|     no|    100|    yes|  no|unknown|  7|  may|     786|       1|   -1|       0| unknown|    yes|\n",
            "| 30|blue-collar| married|secondary|     no|    309|    yes|  no|unknown|  7|  may|    1574|       2|   -1|       0| unknown|    yes|\n",
            "| 29| management| married| tertiary|     no|    199|    yes| yes|unknown|  7|  may|    1689|       4|   -1|       0| unknown|    yes|\n",
            "| 46|blue-collar|  single| tertiary|     no|    460|    yes|  no|unknown|  7|  may|    1102|       2|   -1|       0| unknown|    yes|\n",
            "| 31| technician|  single| tertiary|     no|    703|    yes|  no|unknown|  8|  may|     943|       2|   -1|       0| unknown|    yes|\n",
            "| 35| management|divorced| tertiary|     no|   3837|    yes|  no|unknown|  8|  may|    1084|       1|   -1|       0| unknown|    yes|\n",
            "| 32|blue-collar|  single|  primary|     no|    611|    yes|  no|unknown|  8|  may|     541|       3|   -1|       0| unknown|    yes|\n",
            "| 49|   services| married|secondary|     no|     -8|    yes|  no|unknown|  8|  may|    1119|       1|   -1|       0| unknown|    yes|\n",
            "| 41|     admin.| married|secondary|     no|     55|    yes|  no|unknown|  8|  may|    1120|       2|   -1|       0| unknown|    yes|\n",
            "| 49|     admin.|divorced|secondary|     no|    168|    yes| yes|unknown|  8|  may|     513|       1|   -1|       0| unknown|    yes|\n",
            "+---+-----------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IBM9jzUu8sa",
        "outputId": "15d6acfd-b9d5-4dbb-b6f5-800354fcd923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E3zihxRqMa7"
      },
      "outputs": [],
      "source": [
        "row=df.count()\n",
        "column=len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkC1Q0-eqcqP",
        "outputId": "49d3d01f-a269-4af6-8578-b46d2da6163f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dimension of dataframe is (11162, 17)\n",
            "number of rows are 11162\n",
            "number of columns are 17\n"
          ]
        }
      ],
      "source": [
        "print(f\"dimension of dataframe is {(row,column)}\")\n",
        "print(f\"number of rows are {row}\")\n",
        "print(f\"number of columns are {column}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcMZCGGE4MAn",
        "outputId": "1a90509b-02b4-4c08-bf11-803b001b15e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, deposit: string]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#SUMMARISING EACH COLUMN VALUES\n",
        "df.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD9_StEf58yQ",
        "outputId": "c8cda652-36a2-4923-c20a-b54f6e2bace6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- deposit: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGO4OhnFqvzZ",
        "outputId": "a66dc09d-0694-4ac8-b1d9-221ad4b009f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, deposit: string]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_cGMpByqgY",
        "outputId": "1638dbe8-4a71-4c1d-eab4-fa7b1472f460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11162"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Finding the duplicates if any .Here returns same no of records so  no duplicates in dataframe\n",
        "#df.dropDuplicates().count()\n",
        "df.distinct().count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDFL8rqCE5GF",
        "outputId": "3d69b968-391f-4859-a85c-87e1f48f031a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|  0|  0|      0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|      0|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#finding the occurence of null values in all columns in dataframe\n",
        "df_col=df.columns\n",
        "from pyspark.sql.functions import col,isnan,when,count\n",
        "null_col=df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_col]\n",
        "   )\n",
        "null_col.show()\n",
        "\n",
        "#no null values occured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gggKhqDtpSgt"
      },
      "outputs": [],
      "source": [
        "#REGISTERING DF2 AS SQL TABLE NAMED \"BANK\"\n",
        "df.registerTempTable(\"bank\")\n",
        "\n",
        "#FILTERING UNKNOWN VALUES USING FROM ALL THE COLUMNS USING \"AND\" \"OR\" LOGIC USING SPARKSQL\n",
        "sqlfilter=spark.sql(\"SELECT * FROM bank WHERE job!='unknown' AND education!='unknown' AND marital!='unknown' AND loan!='unknown' AND (poutcome =='failure' OR poutcome == 'success')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUnzW1DBICCI"
      },
      "outputs": [],
      "source": [
        "#STORING IN NEW VARIABLE TO AVOID 'NONETYPE ERROR'\n",
        "df2=sqlfilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Wq6ySoIdtq",
        "outputId": "f0ec10d6-09bc-46ed-932b-4c8ca3f4fb34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------+--------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|         job| marital|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "| 33|    services| married|secondary|     no|   3444|    yes|  no|telephone| 21|  oct|     144|       1|   91|       4| failure|    yes|\n",
            "| 56|  technician| married|secondary|     no|    589|    yes|  no|  unknown| 23|  oct|     518|       1|  147|       2| success|    yes|\n",
            "| 34|      admin.| married| tertiary|     no|    899|    yes|  no|  unknown| 12|  nov|     114|       1|  170|       3| failure|    yes|\n",
            "| 53|     retired| married| tertiary|     no|   2269|     no|  no| cellular| 17|  nov|    1091|       2|  150|       1| success|    yes|\n",
            "| 37|  technician| married|secondary|     no|   5115|    yes|  no| cellular| 17|  nov|    1210|       2|  171|       4| failure|    yes|\n",
            "| 45|entrepreneur| married|secondary|     no|    781|     no| yes| cellular| 17|  nov|     652|       2|  126|       2| failure|    yes|\n",
            "| 46|  unemployed|divorced|secondary|     no|   3354|    yes|  no| cellular| 19|  nov|     522|       1|  174|       1| success|    yes|\n",
            "| 40|  management| married| tertiary|     no|   3352|    yes|  no| cellular| 19|  nov|     639|       2|   27|       1| success|    yes|\n",
            "| 32|  technician| married| tertiary|     no|   4654|    yes| yes| cellular| 20|  nov|     276|       1|  128|       2| failure|    yes|\n",
            "| 30| blue-collar| married|secondary|     no|    501|    yes| yes| cellular| 20|  nov|     994|       1|  177|       1| failure|    yes|\n",
            "| 46|  technician| married| tertiary|     no|      0|     no|  no| cellular| 20|  nov|     531|       1|  167|       1| failure|    yes|\n",
            "| 38|entrepreneur| married| tertiary|     no|   1110|    yes|  no| cellular| 20|  nov|     888|       2|  183|       2| failure|    yes|\n",
            "| 32|    services| married|secondary|     no|    983|    yes|  no| cellular| 20|  nov|     500|       2|  133|       1| failure|    yes|\n",
            "| 31|  unemployed| married|secondary|     no|    314|    yes|  no| cellular| 20|  nov|    1341|       3|  178|       7| failure|    yes|\n",
            "| 50| blue-collar| married|  primary|     no|  12519|    yes|  no| cellular| 21|  nov|     615|       3|   34|       1| failure|    yes|\n",
            "| 47|  technician| married|secondary|     no|      0|     no|  no| cellular| 21|  nov|     591|       1|   10|       1| failure|    yes|\n",
            "| 59|  management| married| tertiary|     no|   7049|     no|  no| cellular| 21|  nov|     530|       1|  163|       2| failure|    yes|\n",
            "| 31|  management| married|secondary|     no|   8629|    yes|  no| cellular| 21|  nov|     957|       1|  184|       2| failure|    yes|\n",
            "| 53| blue-collar| married|secondary|     no|   1777|    yes|  no| cellular| 21|  nov|     796|       5|  154|       1| failure|    yes|\n",
            "| 40|  technician|  single| tertiary|     no|   1646|    yes|  no| cellular|  2|  feb|     215|       1|  242|       2| failure|    yes|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#DISPLAYING AND SUMMARIZING NEW DATA FRAME\n",
        "df2.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jCGftOtshmc",
        "outputId": "f43777b7-5373-4b20-cb9e-202519c30cd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, deposit: string]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxFzVyXvLu51",
        "outputId": "248223da-6455-4042-d845-e66e93d38be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+----------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+-----------------+------------------+--------+-------+\n",
            "|summary|               age|       job| marital|education|default|           balance|housing|loan| contact|               day|month|          duration|          campaign|            pdays|          previous|poutcome|deposit|\n",
            "+-------+------------------+----------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+-----------------+------------------+--------+-------+\n",
            "|  count|              2181|      2181|    2181|     2181|   2181|              2181|   2181|2181|    2181|              2181| 2181|              2181|              2181|             2181|              2181|    2181|   2181|\n",
            "|   mean| 41.84364970197157|      null|    null|     null|   null| 1742.946813388354|   null|null|    null|14.204034846400734| null| 343.5295735900963|1.8211829436038514|202.8578633654287|3.0917010545621273|    null|   null|\n",
            "| stddev|12.855329179952637|      null|    null|     null|   null|3397.7939950723485|   null|null|    null|  8.10108738010334| null|275.48193079367053|1.2274126864078023|121.3097255486155| 2.958246116660583|    null|   null|\n",
            "|    min|                18|    admin.|divorced|  primary|     no|              -938|     no|  no|cellular|                 1|  apr|                 4|                 1|                1|                 1| failure|     no|\n",
            "|    25%|                32|      null|    null|     null|   null|               224|   null|null|    null|                 8| null|               164|                 1|               97|                 1|    null|   null|\n",
            "|    50%|                38|      null|    null|     null|   null|               719|   null|null|    null|                13| null|               263|                 1|              182|                 2|    null|   null|\n",
            "|    75%|                50|      null|    null|     null|   null|              2044|   null|null|    null|                20| null|               432|                 2|              278|                 4|    null|   null|\n",
            "|    max|                88|unemployed|  single| tertiary|    yes|             81204|    yes| yes| unknown|                31|  sep|              2184|                12|              854|                55| success|    yes|\n",
            "+-------+------------------+----------+--------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+-----------------+------------------+--------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.summary().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsxAdlGmOpO5",
        "outputId": "e532020b-c01e-4d32-daec-669677825253"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(poutcome='success'), Row(poutcome='failure')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.select('poutcome').distinct().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy-JXFJkkYZv",
        "outputId": "9d234e91-3025-4966-ffdf-136c1c6e5ef2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, deposit: string, job_indexed: string, marital_indexed: string, education_indexed: string, default_indexed: string, housing_indexed: string, loan_indexed: string, poutcome_indexed: string, label: string]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwCz-VbArEBU",
        "outputId": "17820554-5974-41db-c584-a2c9ad51f326"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/content/drive/MyDrive/7153/spark-3.0.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "22/10/08 12:40:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "22/10/08 12:40:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "Spark context Web UI available at http://1397c3d31138:4041\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1665232850261).\n",
            "Spark session available as 'spark'.\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.0.0\n",
            "      /_/\n",
            "         \n",
            "Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 11.0.16)\n",
            "Type in expressions to have them evaluated.\n",
            "Type :help for more information.\n",
            "\u001b[35m\n",
            "scala> \u001b[0m"
          ]
        }
      ],
      "source": [
        "!spark-shell --driver-class-path sqljdbc41.jar;spark-to-tableau-0.1.0.jar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA7iSoAIouyD"
      },
      "outputs": [],
      "source": [
        "val sqlContext = new org.apache.spark.sql.SQLContext(sc) import TableauDataFrame._\n",
        "val jdbcSqlConnStr = \"jdbc:sqlserver://IP:1433;databaseName=Dbname;user=UserName;password=Password;\"\n",
        "val jdbcDbTable = \"dbo.TableName\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZzDic6vIx9l"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpSuYMpZJXuF"
      },
      "outputs": [],
      "source": [
        "#SELECTING CATEGORICAL COLUMNS ONLY\n",
        "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome']\n",
        "\n",
        "#CREATING AN EMPTY LIST FOR PIPELINE AND ASSEMBLER\n",
        "stages = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxaC_fwEKJI-"
      },
      "outputs": [],
      "source": [
        "#APPLYING FOR LOOP TO INDEX AND ENCODE ALL THE SELECTED COLUMNS\n",
        "#APPLYING STRING INDEXER TO ALL THE CATEGORICAL COLUMNS AND STORING IT IN A NEW COLUMN WITH +INDEXED\n",
        "#APPLYING ONE HOT ENCODER TO ALL THE INDEXED COLUMNS AND STORING IT IN A NEW COLUMN WITH +ENCODED\n",
        "\n",
        "for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + '_indexed')\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"_encoded\"])\n",
        "    stages += [stringIndexer, encoder]\n",
        "\n",
        "#INDEXING PREDICTOR COLUMN 'DEPOSIT' AS LABEL AND FEATURES\n",
        "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
        "\n",
        "#CREATING STAGES FOR BOTH NUMERICAL AND CATEGORICAL COLUMNS\n",
        "stages += [label_stringIdx]\n",
        "numericCols = ['age', 'balance', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "#ADDING BOTH To ASSEMBLER\n",
        "assemblerInputs = [c + \"_encoded\" for c in categoricalColumns] + numericCols\n",
        "\n",
        "#VECTORIZING TO CREATE A NEW FEATURES COLUMN WITH INDEXED AND ENCODED VALUES\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d0jLFu-KR5S"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gDYPRemKmWH"
      },
      "outputs": [],
      "source": [
        "#COMBINING ALL THE STAGES INTO ONE, FITTING DF2 AND TRANSFORMING IT\n",
        "\n",
        "pipeline = Pipeline(stages = stages)\n",
        "pipelineModel = pipeline.fit(df2)\n",
        "df2 = pipelineModel.transform(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX2AVJnkOhd6"
      },
      "outputs": [],
      "source": [
        "#STORING IN NEW VARIABLE TO AVOID 'NONETYPE ERROR'\n",
        "df3=df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE9od5WnKtjQ",
        "outputId": "7399c027-56d4-4f94-e806-1bb16be4836e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+\n",
            "|age|       job|marital|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|job_indexed|   job_encoded|marital_indexed|marital_encoded|education_indexed|education_encoded|default_indexed|default_encoded|housing_indexed|housing_encoded|loan_indexed| loan_encoded|poutcome_indexed|poutcome_encoded|label|            features|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+\n",
            "| 33|  services|married|secondary|     no|   3444|    yes|  no|telephone| 21|  oct|     144|       1|   91|       4| failure|    yes|        5.0|(10,[5],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[5,10,12,14,1...|\n",
            "| 56|technician|married|secondary|     no|    589|    yes|  no|  unknown| 23|  oct|     518|       1|  147|       2| success|    yes|        1.0|(10,[1],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             1.0|       (1,[],[])|  0.0|(23,[1,10,12,14,1...|\n",
            "| 34|    admin.|married| tertiary|     no|    899|    yes|  no|  unknown| 12|  nov|     114|       1|  170|       3| failure|    yes|        2.0|(10,[2],[1.0])|            0.0|  (2,[0],[1.0])|              1.0|    (2,[1],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[2,10,13,14,1...|\n",
            "| 53|   retired|married| tertiary|     no|   2269|     no|  no| cellular| 17|  nov|    1091|       2|  150|       1| success|    yes|        4.0|(10,[4],[1.0])|            0.0|  (2,[0],[1.0])|              1.0|    (2,[1],[1.0])|            0.0|  (1,[0],[1.0])|            0.0|  (1,[0],[1.0])|         0.0|(1,[0],[1.0])|             1.0|       (1,[],[])|  0.0|(23,[4,10,13,14,1...|\n",
            "| 37|technician|married|secondary|     no|   5115|    yes|  no| cellular| 17|  nov|    1210|       2|  171|       4| failure|    yes|        1.0|(10,[1],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[1,10,12,14,1...|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df3.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUAFvPQIQcqh"
      },
      "outputs": [],
      "source": [
        "#Normalisation\n",
        "#SELECTING ONLY THE ENCODED COLUMNS TO NORMALIZE\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "norm_vars=['features','job_encoded','marital_encoded','loan_encoded','default_encoded','education_encoded','housing_encoded','poutcome_encoded']\n",
        "\n",
        "#USING MIN-MAX SCALER FUNCTION TO SCLE IT DOWN BETWEEN 0 AND 1\n",
        "scaler = [MinMaxScaler(inputCol=scale_features ,outputCol=scale_features+ \"_SCALED\") for scale_features in norm_vars]\n",
        "\n",
        "#PIPELINING FOR ALL THE COLUMNS AND FITTING IT AGAIN TO DF2\n",
        "pipeline = Pipeline(stages=scaler)\n",
        "scalerModel =  pipeline.fit(df2)\n",
        "scaledData = scalerModel.transform(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr6iAVi8Senf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wa2iN8GTRRr",
        "outputId": "b461274e-a299-42e1-bea2-a87f7d269c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+\n",
            "|age|       job|marital|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|job_indexed|   job_encoded|marital_indexed|marital_encoded|education_indexed|education_encoded|default_indexed|default_encoded|housing_indexed|housing_encoded|loan_indexed| loan_encoded|poutcome_indexed|poutcome_encoded|label|            features|     features_SCALED|job_encoded_SCALED|marital_encoded_SCALED|loan_encoded_SCALED|default_encoded_SCALED|education_encoded_SCALED|housing_encoded_SCALED|poutcome_encoded_SCALED|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+\n",
            "| 33|  services|married|secondary|     no|   3444|    yes|  no|telephone| 21|  oct|     144|       1|   91|       4| failure|    yes|        5.0|(10,[5],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[5,10,12,14,1...|(23,[5,10,12,14,1...|    (10,[5],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [1.0]|\n",
            "| 56|technician|married|secondary|     no|    589|    yes|  no|  unknown| 23|  oct|     518|       1|  147|       2| success|    yes|        1.0|(10,[1],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             1.0|       (1,[],[])|  0.0|(23,[1,10,12,14,1...|(23,[1,10,12,14,1...|    (10,[1],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [0.0]|\n",
            "| 34|    admin.|married| tertiary|     no|    899|    yes|  no|  unknown| 12|  nov|     114|       1|  170|       3| failure|    yes|        2.0|(10,[2],[1.0])|            0.0|  (2,[0],[1.0])|              1.0|    (2,[1],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[2,10,13,14,1...|(23,[2,10,13,14,1...|    (10,[2],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [0.0,1.0]|                 [0.0]|                  [1.0]|\n",
            "| 53|   retired|married| tertiary|     no|   2269|     no|  no| cellular| 17|  nov|    1091|       2|  150|       1| success|    yes|        4.0|(10,[4],[1.0])|            0.0|  (2,[0],[1.0])|              1.0|    (2,[1],[1.0])|            0.0|  (1,[0],[1.0])|            0.0|  (1,[0],[1.0])|         0.0|(1,[0],[1.0])|             1.0|       (1,[],[])|  0.0|(23,[4,10,13,14,1...|(23,[4,10,13,14,1...|    (10,[4],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [0.0,1.0]|                 [1.0]|                  [0.0]|\n",
            "| 37|technician|married|secondary|     no|   5115|    yes|  no| cellular| 17|  nov|    1210|       2|  171|       4| failure|    yes|        1.0|(10,[1],[1.0])|            0.0|  (2,[0],[1.0])|              0.0|    (2,[0],[1.0])|            0.0|  (1,[0],[1.0])|            1.0|      (1,[],[])|         0.0|(1,[0],[1.0])|             0.0|   (1,[0],[1.0])|  0.0|(23,[1,10,12,14,1...|(23,[1,10,12,14,1...|    (10,[1],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [1.0]|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+-------+-----------+--------------+---------------+---------------+-----------------+-----------------+---------------+---------------+---------------+---------------+------------+-------------+----------------+----------------+-----+--------------------+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#DISPLAYING ALL THE NORMALIZED VALUES\n",
        "scaledData.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efzF_CjJTUcE"
      },
      "outputs": [],
      "source": [
        "#SELECTING ONLY THE REQUIRED COLUMNS FOR FURTHER SUPERVISED AND UNSUPERVISED LEARNING\n",
        "\n",
        "df4=scaledData.select('deposit','label','features','job_encoded_SCALED','marital_encoded_SCALED','loan_encoded_SCALED','default_encoded_SCALED','education_encoded_SCALED','housing_encoded_SCALED','poutcome_encoded_SCALED','features_SCALED')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfLLAibxThYL",
        "outputId": "80a4425c-37b8-4718-aeb4-4d331883a109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+--------------------+\n",
            "|deposit|label|            features|job_encoded_SCALED|marital_encoded_SCALED|loan_encoded_SCALED|default_encoded_SCALED|education_encoded_SCALED|housing_encoded_SCALED|poutcome_encoded_SCALED|     features_SCALED|\n",
            "+-------+-----+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+--------------------+\n",
            "|    yes|  0.0|(23,[5,10,12,14,1...|    (10,[5],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [1.0]|(23,[5,10,12,14,1...|\n",
            "|    yes|  0.0|(23,[1,10,12,14,1...|    (10,[1],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [0.0]|(23,[1,10,12,14,1...|\n",
            "|    yes|  0.0|(23,[2,10,13,14,1...|    (10,[2],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [0.0,1.0]|                 [0.0]|                  [1.0]|(23,[2,10,13,14,1...|\n",
            "|    yes|  0.0|(23,[4,10,13,14,1...|    (10,[4],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [0.0,1.0]|                 [1.0]|                  [0.0]|(23,[4,10,13,14,1...|\n",
            "|    yes|  0.0|(23,[1,10,12,14,1...|    (10,[1],[1.0])|             [1.0,0.0]|              [1.0]|                 [1.0]|               [1.0,0.0]|                 [0.0]|                  [1.0]|(23,[1,10,12,14,1...|\n",
            "+-------+-----+--------------------+------------------+----------------------+-------------------+----------------------+------------------------+----------------------+-----------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2BnbIzBTno8",
        "outputId": "c182fe4a-7fe7-4e34-e386-ccf3be5bc791"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(age=33, job='services', marital='married', education='secondary', default='no', balance=3444, housing='yes', loan='no', contact='telephone', day=21, month='oct', duration=144, campaign=1, pdays=91, previous=4, poutcome='failure', deposit='yes', job_indexed=5.0, job_encoded=SparseVector(10, {5: 1.0}), marital_indexed=0.0, marital_encoded=SparseVector(2, {0: 1.0}), education_indexed=0.0, education_encoded=SparseVector(2, {0: 1.0}), default_indexed=0.0, default_encoded=SparseVector(1, {0: 1.0}), housing_indexed=1.0, housing_encoded=SparseVector(1, {}), loan_indexed=0.0, loan_encoded=SparseVector(1, {0: 1.0}), poutcome_indexed=0.0, poutcome_encoded=SparseVector(1, {0: 1.0}), label=0.0, features=SparseVector(23, {5: 1.0, 10: 1.0, 12: 1.0, 14: 1.0, 16: 1.0, 17: 1.0, 18: 33.0, 19: 3444.0, 20: 1.0, 21: 91.0, 22: 4.0}))]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.take(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiiZQj6qTxkS"
      },
      "source": [
        "KMeans Clustering-Unsupervised Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-k-roGTTxBL"
      },
      "outputs": [],
      "source": [
        "# Perform unsupervised learning on df2 with k-means\n",
        "# You can use whole df2 as both training and testing data,\n",
        "# Evaluate the clustering result using Accuracy.\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDmeVc2QUVAZ",
        "outputId": "08df115b-8ecd-4b6a-b6da-2620f9003e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "|  0.0|         0|\n",
            "+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "#PERFORMING KMEANS CLUSTERING ON DF2 DATA FRAME\n",
        "#WHOLE DATA IS USED AS TRAINING AND TESTING DATA AS IT IS UNSUPERVISED\n",
        "# Trains a k-means model.\n",
        "kmeans = KMeans().setK(2).setSeed(742).setFeaturesCol(\"features\")\n",
        "model = kmeans.fit(df4)\n",
        "# Make predictions\n",
        "predictions = model.transform(df4)\n",
        "predictions.select('label', 'prediction').show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwWZ8He5UVDy"
      },
      "outputs": [],
      "source": [
        "#APPLYING KMEANS USING ELBOW METHOD TO GET THE OPTIMAL VALUE OF K TO HELP IN ANALYSIS IN REPORT\n",
        "# Trains a k-means model.\n",
        "kmeans3=KMeans(featuresCol=\"features\",k=3)\n",
        "kmeans2=KMeans(featuresCol=\"features\",k=2)\n",
        "model_k3 = kmeans3.fit(df4)\n",
        "model_k2 = kmeans2.fit(df4)\n",
        "#wssse_k3 = computeCost(df4)\n",
        "#wssse_k2 = model_k2.computeCost(df4)\n",
        "#evaluator = ClusteringEvaluator()\n",
        "#split_vecs = df4.map(lambda x: (x[0], np.split(x[1], 2)))\n",
        "#costs_per_split = [KMeansModel(model.Cs[i]).computeCost(split_vecs.map(lambda x: x[1][i])) for i in range(2)]\n",
        "#wssse_k3 = model_k3.computeCost(df4)\n",
        "print(\"With K=3\")\n",
        "print(\"Within Set Sum of Squared Errors = \" + str(wssse_k3))\n",
        "print('--'*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW4qNJVxY2ZK"
      },
      "outputs": [],
      "source": [
        "silhouette = evaluator.evaluate(df4)\n",
        "print(\"With K=3\")\n",
        "print(\"Within Set Sum of Squared Errors = \" + str(wssse_k3))\n",
        "print('--'*30)\n",
        "print(\"With K=2\")\n",
        "print(\"Within Set Sum of Squared Errors = \" + str(wssse_k2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G76hgPgEUVGv",
        "outputId": "4de1895d-f3e5-4fc3-d954-0a397410b0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=2\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=3\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=4\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=5\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=6\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=7\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n",
            "Silhouette with squared euclidean distance = 0.9955086503489643\n",
            "With K=8\n",
            "Within Set Sum of Squared Errors = 0.9955086503489643\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#APPLYING FOR LOOP FOR REST OF THE VALUES OF K\n",
        "for k in range(2,9):\n",
        "    kmeans = KMeans(featuresCol='features_SCALED',k=k)\n",
        "    model = kmeans.fit(df4)\n",
        "    #cost = model.computeCost(dataset)\n",
        "#print(\"Within Set Sum of Squared Errors = \" + str(cost))\n",
        "   # wssse = model.computeCost(df4)\n",
        "    evaluator = ClusteringEvaluator()\n",
        "    silhouette = evaluator.evaluate(predictions)\n",
        "    #print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
        "    print(\"With K={}\".format(k))\n",
        "    print(\"Within Set Sum of Squared Errors = \" + str(silhouette))\n",
        "    print('--'*30)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5qwAA2gUVpD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QeFngwC4QkcXKRD6_YlEwDIsES24sPVB",
      "authorship_tag": "ABX9TyO1mT1LlqxTt8408Q6TrGDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}